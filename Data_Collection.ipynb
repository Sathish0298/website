{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a0d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2bc036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for https://www.amazon.in/Omron-Automatic-Intellisense-Technology-Measurement/product-reviews/B00F38B3NW?th=1 started\n",
      "Scraping for https://www.amazon.in/Omron-Automatic-Intellisense-Technology-Measurement/product-reviews/B00F38B3NW?th=1 completed\n"
     ]
    }
   ],
   "source": [
    "def amazon_review_scraper(url, page):\n",
    "    url = f\"{url}&pageNumber={page}\"\n",
    "\n",
    "    reviews = []\n",
    "\n",
    "    user_agent = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url=url, headers=user_agent)\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "    for review in soup.find_all(\"div\", {\"class\": \"a-section review aok-relative\"}):\n",
    "        name = review.find(\"span\", {\"class\": \"a-profile-name\"}).text\n",
    "        rating = review.find(\"i\", {\"data-hook\": \"review-star-rating\"}).text\n",
    "        comments = review.find(\n",
    "            \"div\", {\"class\": \"a-row a-spacing-small review-data\"}\n",
    "        ).text\n",
    "\n",
    "        data = {\n",
    "            \"Name\": name,\n",
    "            \"Rating\": rating,\n",
    "            \"Comments\": comments,\n",
    "        }\n",
    "\n",
    "        reviews.append(data)\n",
    "\n",
    "    return reviews\n",
    "\n",
    "\n",
    "urls = [\n",
    "    \"https://www.amazon.in/Omron-Automatic-Intellisense-Technology-Measurement/product-reviews/B00F38B3NW\",\n",
    "]\n",
    "\n",
    "\n",
    "def scrape_reviews(urls):\n",
    "    all_reviews = []\n",
    "    for url in urls:\n",
    "        url = url + \"?th=1\"\n",
    "        print(f\"Scraping for {url} started\")\n",
    "        num_pages = 2\n",
    "        for page in range(2, num_pages):\n",
    "            reviews = amazon_review_scraper(url, page)\n",
    "\n",
    "            all_reviews.extend(\n",
    "                [\n",
    "                    f\"Rating: {review['Rating']}, Comments: {review['Comments']}\"\n",
    "                    for review in reviews\n",
    "                ]\n",
    "            )\n",
    "        print(f\"Scraping for {url} completed\")\n",
    "    return all_reviews\n",
    "\n",
    "\n",
    "all_reviews = scrape_reviews(urls)\n",
    "\n",
    "amazon_df = pd.DataFrame(all_reviews)\n",
    "\n",
    "# Save DataFrame to Excel file\n",
    "amazon_df.to_excel(\"data/amazon_reviews.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc317f43-5e54-4e41-b67e-c3cf07c029ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Started\n"
     ]
    }
   ],
   "source": [
    "def flipkart_review_scraper(url, page):\n",
    "    url = f\"{url}&page={page}\"\n",
    "\n",
    "    reviews = []\n",
    "\n",
    "    user_agent = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url=url, headers=user_agent)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    for review in soup.find_all(\n",
    "        \"div\", {\"class\": \"_27M-vq\"}\n",
    "    ):  # Updated class for review container\n",
    "        name = review.find(\n",
    "            \"p\", {\"class\": \"_2sc7ZR _2V5EHH\"}\n",
    "        ).text  # Updated class for reviewer's name\n",
    "        rating = review.find(\n",
    "            \"div\", {\"class\": \"_3LWZlK\"}\n",
    "        ).text  # Updated class for rating\n",
    "        comments = review.find(\n",
    "            \"div\", {\"class\": \"t-ZTKy\"}\n",
    "        ).text  # Updated class for review comments\n",
    "        comments = re.sub(\n",
    "            r\"\\s*READ\\s+MORE\\s*\", \"\", comments\n",
    "        )  # Remove 'READ MORE' links if present\n",
    "\n",
    "        data = {\n",
    "            \"Name\": name,\n",
    "            \"Rating\": rating,\n",
    "            \"Comments\": comments.strip(),\n",
    "        }\n",
    "\n",
    "        reviews.append(data)\n",
    "\n",
    "    return reviews\n",
    "\n",
    "\n",
    "url = \"https://www.flipkart.com/samsung-galaxy-watch4-bluetooth-4-0cm-bt-calling-health-monitoring-fall-detection/product-reviews/itmb9f795a3e99ce?pid=SMWGBYRGYCHRVMXV&lid=LSTSMWGBYRGYCHRVMXVV14CCB&marketplace=FLIPKART\"\n",
    "print(\"Scraping Started\")\n",
    "\n",
    "all_reviews = []\n",
    "\n",
    "for page in range(1, 31):\n",
    "    reviews = flipkart_review_scraper(url, page)\n",
    "    all_reviews.extend(\n",
    "        [\n",
    "            f\"Rating: {review['Rating']}, Comments: {review['Comments']}\"\n",
    "            for review in reviews\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(\"Scraping Completed\")\n",
    "\n",
    "flipkart_df = pd.DataFrame(all_reviews)\n",
    "\n",
    "# Save DataFrame to Excel file\n",
    "flipkart_df.to_excel(\"data/flipkart_reviews.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b46139a-8fe9-42e7-8628-5277e193e5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Started\n",
      "Scraping Completed\n"
     ]
    }
   ],
   "source": [
    "def snapdeal_review_scraper(url, page):\n",
    "    url = f\"{url}?page={page}\"\n",
    "    reviews = []\n",
    "\n",
    "    user_agent = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url=url, headers=user_agent)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    reviews_skipped = 0  # Counter to track the number of reviews skipped\n",
    "\n",
    "    for review in soup.find_all(\"div\", {\"class\": \"user-review\"}):\n",
    "        if reviews_skipped < 2:\n",
    "            reviews_skipped += 1\n",
    "            continue  # Skip the first two reviews\n",
    "\n",
    "        rating_elements = review.find_all(\"i\", class_=\"sd-icon sd-icon-star active\")\n",
    "        rating = len(rating_elements)\n",
    "        name = review.find(\"div\", {\"class\": \"_reviewUserName\"}).get(\"title\")\n",
    "        comments = review.find(\"p\").text\n",
    "\n",
    "        data = {\n",
    "            \"Name\": name,\n",
    "            \"Rating\": rating,\n",
    "            \"Comments\": comments,\n",
    "        }\n",
    "\n",
    "        reviews.append(data)\n",
    "\n",
    "    return reviews\n",
    "\n",
    "\n",
    "url = \"https://www.snapdeal.com/product/omron-auto-b-p-monitor/1290000232/reviews\"\n",
    "\n",
    "all_reviews = []\n",
    "\n",
    "print(\"Scraping Started\")\n",
    "\n",
    "for page in range(1, 131):\n",
    "    reviews = snapdeal_review_scraper(url, page)\n",
    "    all_reviews.extend(\n",
    "        [\n",
    "            f\"Rating: {review['Rating']}, Comments: {review['Comments']}\"\n",
    "            for review in reviews\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(\"Scraping Completed\")\n",
    "\n",
    "snapdeal_df = pd.DataFrame(all_reviews)\n",
    "\n",
    "# Save DataFrame to Excel file\n",
    "snapdeal_df.to_excel(\"data/snapdeal_reviews.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
